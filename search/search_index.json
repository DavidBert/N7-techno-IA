{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"AI technologies During this course you will: Learn about code versioning and containers to share your code and produce reproducible results Learn how to developp a recommender system Learn to train autonomous agents to play video games using Reinforcement Learning Learn to gain interpretability on your machine learning models Knowledge requirements Python Tutorial Elementary statistic tools Data Exploration and Clustering . Machine Learning High Dimensional & Deep Learning","title":"Home"},{"location":"index.html#ai-technologies","text":"During this course you will: Learn about code versioning and containers to share your code and produce reproducible results Learn how to developp a recommender system Learn to train autonomous agents to play video games using Reinforcement Learning Learn to gain interpretability on your machine learning models","title":"AI technologies"},{"location":"index.html#knowledge-requirements","text":"Python Tutorial Elementary statistic tools Data Exploration and Clustering . Machine Learning High Dimensional & Deep Learning","title":"Knowledge requirements"},{"location":"dev.html","text":"Development for Data Scientist: Pytorch and Python Script Course Course notebook: Notebook","title":"Python Scripts"},{"location":"dev.html#development-for-data-scientist","text":"","title":"Development for Data Scientist:"},{"location":"dev.html#pytorch-and-python-script","text":"","title":"Pytorch and Python Script"},{"location":"dev.html#course","text":"","title":"Course"},{"location":"dev.html#course-notebook","text":"Notebook","title":"Course notebook:"},{"location":"docker.html","text":"Development for Data Scientist: Docker Course Slides","title":"Introduction to Docker"},{"location":"docker.html#development-for-data-scientist","text":"","title":"Development for Data Scientist:"},{"location":"docker.html#docker","text":"","title":"Docker"},{"location":"docker.html#course","text":"Slides","title":"Course"},{"location":"evaluation.html","text":"Evaluation The evaluation is associated to the DEFI-IA Objective You will be evaluated on your capacity of acting like a Data Scientist , i.e. Handle a new dataset and explore it. Find a solution to address the defi's problem with a high score (above baseline). Explain the choosen algorithm. Write a complete pipeline to easily reproduce the results. Justify the choice of the algorithms and the environment (CPU/GPU, Cloud etc..). Share it and make your results easily reproducible (Git - docker, conda environment.). Notations Project - ( 60% ): a Git repository. The git should contain a clear markdown Readme, which describes ( 33% ) Which result you achieved? In which computation time? On which engine? What do I have to install to be able to reproduce the code? Which command do I have to run to reproduce the results? The code has to be easily reproducible. ( 33% ) Packages required has to be well described. (a requirements.txt files is the best) Conda command or docker command can be furnish The code should be clear and easily readable. ( 33% ) Final results can be run in a script and not a notebook. Only final code can be found in this script. Rapport - ( 40% ) 10 pages maximum: Quality of the presentation. 25% In-Deep explanation of the chosen algorithm. 25% Choice of the tools-infrastructure used. 25% Results you obtained. 25% Other details Group of 4 to 5 people (DEFI IA's team).","title":"Evaluation"},{"location":"evaluation.html#evaluation","text":"The evaluation is associated to the DEFI-IA","title":"Evaluation"},{"location":"evaluation.html#objective","text":"You will be evaluated on your capacity of acting like a Data Scientist , i.e. Handle a new dataset and explore it. Find a solution to address the defi's problem with a high score (above baseline). Explain the choosen algorithm. Write a complete pipeline to easily reproduce the results. Justify the choice of the algorithms and the environment (CPU/GPU, Cloud etc..). Share it and make your results easily reproducible (Git - docker, conda environment.).","title":"Objective"},{"location":"evaluation.html#notations","text":"Project - ( 60% ): a Git repository. The git should contain a clear markdown Readme, which describes ( 33% ) Which result you achieved? In which computation time? On which engine? What do I have to install to be able to reproduce the code? Which command do I have to run to reproduce the results? The code has to be easily reproducible. ( 33% ) Packages required has to be well described. (a requirements.txt files is the best) Conda command or docker command can be furnish The code should be clear and easily readable. ( 33% ) Final results can be run in a script and not a notebook. Only final code can be found in this script. Rapport - ( 40% ) 10 pages maximum: Quality of the presentation. 25% In-Deep explanation of the chosen algorithm. 25% Choice of the tools-infrastructure used. 25% Results you obtained. 25%","title":"Notations"},{"location":"evaluation.html#other-details","text":"Group of 4 to 5 people (DEFI IA's team).","title":"Other details"},{"location":"gcloud.html","text":"Development for Data Scientist: Introduction to Google Cloud Computing Course Slides Practical Session In this session, you will train a neural network to colorize black and white images using virtual machines on Google Cloud . You will have to: Set up a new GCloud instance with GPU capacities Write your Python scripts on your local machine Send your code to your GCloud Instance Run your code on the cloud virtual machine Monitor your code running on the virtual machine Get your results and send them to your local machine The solution is available here. Try to complete the practical session without looking at it! Set up your virtual machine First follow the GCloud setup process described here . The python script Cloud providers charge by the hour, so cloud computing can quickly get expensive. A good practice consists of doing most of the code development on your local hardware before sending it to your cloud instances. That is what you are going to do in this practical session. You will run one small iteration of your code on your local machine to test your code and then send it to your virtual machine. We will be working with the Landscapes dataset composed of 4000 images in seven categories of landscapes (city, road, mountain, lake, ocean, field, and forest). Instead of using it to train a classifier, we will use it to train a neural network to colorize black and white images. Create a script download_landscapes.sh with the following content and execute it to download and extract the dataset. cd data wget https://github.com/ml5js/ml5-data-and-models/raw/master/datasets/images/landscapes/landscapes_small.zip mkdir landscapes unzip landscapes_small.zip -d landscapes rm landscapes_small.zip rm -r landscapes/__MACOSX cd .. We will use a particular category of neural networks to perform the colorization operation: Unets . Initially designed for Biomedical Image Segmentation, Unets offer state-of-the-art performances in many segmentation tasks. These performances are mainly due to the skip connections used in UNets architectures. Indeed, Unets are a particular form of Auto-Encoders using skip connections between corresponding layers of the encoder and the decoder. Create a new file named unet.py where you will define the following Unet network: Help yourself with the above image to implement a Unet network using the following template: import torch import torch.nn as nn import torch.nn.functional as F def double_conv(in_channels, out_channels): # returns a block compsed of two Convolution layers with ReLU activation function return nn.Sequential( nn.Conv2d(in_channels, out_channels, 3, padding=1), nn.ReLU(), nn.Conv2d(out_channels, out_channels, 3, padding=1), nn.ReLU() ) class DownSampleBlock(nn.Module): def __init__(self, in_channels, out_channels): super().__init__() self.conv_block = ... self.maxpool = ... def forward(self, x): x_skip = ... out = ... return out , x_skip class UpSampleBlock(nn.Module): def __init__(self, in_channels, out_channels): super().__init__() self.conv_block = ... self.upsample = ... # use nn.Upsample def forward(self, x, x_skip): x = self.upsample(x) x = torch.cat([x, x_skip], dim=1) # concatenates x and x_skip x = self.conv_block(x) return x class UNet(nn.Module): def __init__(self): super().__init__() self.downsample_block_1 = ... self.downsample_block_2 = ... self.downsample_block_3 = ... self.middle_conv_block = double_conv(128, 256) self.upsample_block_3 = ... self.upsample_block_2 = ... self.upsample_block_1 = ... self.last_conv = nn.Conv2d(32, 3, 1) def forward(self, x): x, x_skip1 = ... x, x_skip2 = ... x, x_skip3 = ... x = self.middle_conv_block(x) x = #use upsampleblock_3 and x_skip3 x = #use upsampleblock_2 and x_skip2 x = #use upsampleblock_1 and x_skip1 out = self.(x) return out if __name__=='__main__': x = torch.rand(16,1,224,224) net = UNet() y = net(x) assert y.shape == (16,3,224,224) print('Shapes OK') Check that your network is producing correct outputs by running your file with: python unet.py The Training script You will now implement the training procedure. Training a network to colorize images is a supervised regression problem. Consider $x$ a grayscaled image and $y$ its corresponding colored image. Training a parametrized network $f_\\theta$ to predict colorized images $\u0177$ amounts to minimizing the distance between the prediction $\u0177$ and the actual $y$. That is to say minimizing $MSE(y, f_\\theta(x))$. Create a new file data_utils.py that will handle the dataset: from torchvision.datasets.folder import ImageFolder, default_loader, IMG_EXTENSIONS from torch.utils.data import DataLoader import torchvision.transforms as transforms class ImageFolderGrayColor(ImageFolder): def __init__( self, root, transform=None, target_transform=None, ): super(ImageFolder, self).__init__(root=root, loader=default_loader, transform=transform, extensions=IMG_EXTENSIONS, target_transform=target_transform) #TODO \u00e0 modifier def __getitem__(self, index): \"\"\" Args: index (int): Index Returns: tuple: (sample, target) where target is class_index of the target class. \"\"\" path, _ = self.samples[index] sample = self.loader(path) if self.target_transform is not None: target = self.target_transform(sample) if self.transform is not None: sample = self.transform(sample) return sample, target def get_colorized_dataset_loader(path, **kwargs): source_process = transforms.Compose( [transforms.Resize((224, 224)), transforms.Grayscale(num_output_channels=1), transforms.ToTensor(), transforms.Normalize(mean=[0.5], std=[0.5])]) target_process = transforms.Compose( [transforms.Resize((224, 224)), transforms.ToTensor()]) dataset = ImageFolderGrayColor(path, source_process, target_process) return DataLoader(dataset, **kwargs) Create a new file colorize.py and fill the train method in the following canvas (you can inspire yourself from the one in the MNIST example. Be careful, however, in your criterion choice): import argparse # to parse script arguments from statistics import mean # to compute the mean of a list from tqdm import tqdm #used to generate progress bar during training import torch import torch.optim as optim from torch.utils.tensorboard import SummaryWriter from torchvision.utils import make_grid #to generate image grids, will be used in tensorboard from data_utils import get_colorized_dataset_loader # dataloarder from unet import UNet # setting device on GPU if available, else CPU device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') def train(net, optimizer, loader, epochs=5, writer=None): criterion = ... for epoch in range(epochs): running_loss = [] t = tqdm(loader) for x, y in t: # x: black and white image, y: colored image ... ... ... ... ... ... ... ... if writer is not None: #Logging loss in tensorboard writer.add_scalar('training loss', mean(running_loss), epoch) # Logging a sample of inputs in tensorboard input_grid = make_grid(x[:16].detach().cpu()) writer.add_image('Input', input_grid, epoch) # Logging a sample of predicted outputs in tensorboard colorized_grid = make_grid(outputs[:16].detach().cpu()) writer.add_image('Predicted', colorized_grid, epoch) # Logging a sample of ground truth in tensorboard original_grid = make_grid(y[:16].detach().cpu()) writer.add_image('Ground truth', original_grid, epoch) return mean(running_loss) if __name__=='__main__': parser = argparse.ArgumentParser() parser.add_argument('--data_path', type=str, default = 'data/landscapes', help='dataset path') parser.add_argument('--batch_size', type=int, default = int(32), help='batch_size') parser.add_argument('--epochs', type=int, default = int(10), help='number of epochs') parser.add_argument('--lr', type=float, default = float(1e-3), help='learning rate') args = parser.parse_args() data_path = args.data_path batch_size = args.batch_size epochs = args.epochs lr = args.lr unet = UNet().cuda() loader = get_colorized_dataset_loader(path=data_path, batch_size=batch_size, shuffle=True, num_workers=4) optimizer = optim.Adam(unet.parameters(), lr=lr) writer = SummaryWriter('runs/UNet') train(unet, optimizer, loader, epochs=epochs, writer=writer) writer.add_graph(unet) # Save model weights torch.save(unet.state_dict(), 'unet.pth') Training on GCloud You now have everything to run your code on GCloud. Fire up your GCloud instance. On a terminal, connect to your instance using the following command (replace the zone and instance name with yours): gcloud compute ssh --zone \"europe-west1-d\" \"your_instance_name\" Create a folder Workspace on your virtual machine: mkdir Workspace You can copy a file from your local machine to the virtual machine using the following command on your local terminal: gcloud compute scp [your_file_path] your_instance_name:Workspace/ --zone \"europe-west1-d\" Conversly, you can copy a from your virtual machine to your local machine the following command on your local terminal: gcloud compute scp bsf.pth your_instance_name:Workspace/ --zone \"europe-west1-d\" Add the --recurse argument to your command if you want to copy a folder. Copy the folder containing all your code into your virtual machine's Workspace folder. Also, copy the download_landscapes.sh file into your VM and execute it. You should now be able to run your python script and thus learn to colorize images. Run your script for one entire epoch to check that everything is working fine. We will now run our script for a few more epochs, but before that, we will create an ssh tunnel between our local machine and the virtual machine. Run the following command on your local machine with the correct name for your virtual machine (use your correct zone). gcloud compute ssh --ssh-flag=\"-L 8898:localhost:8898\" --zone \"us-central1-b\" \"example_instance_name\" This command connects you to your virtual machine and forwards its port 8898 to your local machine's port 8898 (you can change the port value if needed). Thanks to that, you will get access to the tensorboard interface running on the virtual machine through your local machine. Now on this terminal window, run the following command: tensorboard --logdir runs --port 8898 On another terminal, connect to your virtual machine and run your script with a few more epochs (like 10 for instance). On your web browser, go to the following adress: http://localhost:8898/ You should be able to access tensorboard. Check on your network graph. You should see the U shape of your Unet. You can now visualize the progression of your network while it is training in the images tab. Bonus synchronize with Rsync An easy way to synchronize your code with your VM is to use rsync Install rsync on your virtual machine : sudo apt-get install rsync Add the public key you\u2019re going to use to connect to the VM to the VM\u2019s ~/.ssh/authorized_keys On the virtual machine: touch ~/.ssh/authorized_keys nano ~/.ssh/authorized_keys Copy the content of your public key (It is usually located in ~/.ssh/id_rsa.pub on your local machine) in the opened file. Press ctrl+x then y then enter to save. Now to synchronize a folder, find the IP of your virtual machine in the GCloud interface: To synchronize your folder on your local machine (for instance, named test_gcloud ) with a distant folder on the virtual machine (located, for example, in Workspace/test_gcloud): rsync -r [VM_IP_ADRESS]:Workspace/test_gcloud/ test_gcloud/ To synchronize a distant folder on the virtual machine with a folder on your local machine : rsync -r test_gcloud/ [VM_IP_ADRESS]:Workspace/test_gcloud/ You can find more information on the rsync command here (in french) You can stop your VM using the GCloud interface or just by running the following command: sudo shutdown -h now","title":"Development for Data Scientist:"},{"location":"gcloud.html#development-for-data-scientist","text":"","title":"Development for Data Scientist:"},{"location":"gcloud.html#introduction-to-google-cloud-computing","text":"","title":"Introduction to Google Cloud Computing"},{"location":"gcloud.html#course","text":"Slides","title":"Course"},{"location":"gcloud.html#practical-session","text":"In this session, you will train a neural network to colorize black and white images using virtual machines on Google Cloud . You will have to: Set up a new GCloud instance with GPU capacities Write your Python scripts on your local machine Send your code to your GCloud Instance Run your code on the cloud virtual machine Monitor your code running on the virtual machine Get your results and send them to your local machine The solution is available here. Try to complete the practical session without looking at it!","title":"Practical Session"},{"location":"gcloud.html#set-up-your-virtual-machine","text":"First follow the GCloud setup process described here .","title":"Set up your virtual machine"},{"location":"gcloud.html#the-python-script","text":"Cloud providers charge by the hour, so cloud computing can quickly get expensive. A good practice consists of doing most of the code development on your local hardware before sending it to your cloud instances. That is what you are going to do in this practical session. You will run one small iteration of your code on your local machine to test your code and then send it to your virtual machine. We will be working with the Landscapes dataset composed of 4000 images in seven categories of landscapes (city, road, mountain, lake, ocean, field, and forest). Instead of using it to train a classifier, we will use it to train a neural network to colorize black and white images. Create a script download_landscapes.sh with the following content and execute it to download and extract the dataset. cd data wget https://github.com/ml5js/ml5-data-and-models/raw/master/datasets/images/landscapes/landscapes_small.zip mkdir landscapes unzip landscapes_small.zip -d landscapes rm landscapes_small.zip rm -r landscapes/__MACOSX cd .. We will use a particular category of neural networks to perform the colorization operation: Unets . Initially designed for Biomedical Image Segmentation, Unets offer state-of-the-art performances in many segmentation tasks. These performances are mainly due to the skip connections used in UNets architectures. Indeed, Unets are a particular form of Auto-Encoders using skip connections between corresponding layers of the encoder and the decoder. Create a new file named unet.py where you will define the following Unet network: Help yourself with the above image to implement a Unet network using the following template: import torch import torch.nn as nn import torch.nn.functional as F def double_conv(in_channels, out_channels): # returns a block compsed of two Convolution layers with ReLU activation function return nn.Sequential( nn.Conv2d(in_channels, out_channels, 3, padding=1), nn.ReLU(), nn.Conv2d(out_channels, out_channels, 3, padding=1), nn.ReLU() ) class DownSampleBlock(nn.Module): def __init__(self, in_channels, out_channels): super().__init__() self.conv_block = ... self.maxpool = ... def forward(self, x): x_skip = ... out = ... return out , x_skip class UpSampleBlock(nn.Module): def __init__(self, in_channels, out_channels): super().__init__() self.conv_block = ... self.upsample = ... # use nn.Upsample def forward(self, x, x_skip): x = self.upsample(x) x = torch.cat([x, x_skip], dim=1) # concatenates x and x_skip x = self.conv_block(x) return x class UNet(nn.Module): def __init__(self): super().__init__() self.downsample_block_1 = ... self.downsample_block_2 = ... self.downsample_block_3 = ... self.middle_conv_block = double_conv(128, 256) self.upsample_block_3 = ... self.upsample_block_2 = ... self.upsample_block_1 = ... self.last_conv = nn.Conv2d(32, 3, 1) def forward(self, x): x, x_skip1 = ... x, x_skip2 = ... x, x_skip3 = ... x = self.middle_conv_block(x) x = #use upsampleblock_3 and x_skip3 x = #use upsampleblock_2 and x_skip2 x = #use upsampleblock_1 and x_skip1 out = self.(x) return out if __name__=='__main__': x = torch.rand(16,1,224,224) net = UNet() y = net(x) assert y.shape == (16,3,224,224) print('Shapes OK') Check that your network is producing correct outputs by running your file with: python unet.py The","title":"The python script"},{"location":"gcloud.html#training-script","text":"You will now implement the training procedure. Training a network to colorize images is a supervised regression problem. Consider $x$ a grayscaled image and $y$ its corresponding colored image. Training a parametrized network $f_\\theta$ to predict colorized images $\u0177$ amounts to minimizing the distance between the prediction $\u0177$ and the actual $y$. That is to say minimizing $MSE(y, f_\\theta(x))$. Create a new file data_utils.py that will handle the dataset: from torchvision.datasets.folder import ImageFolder, default_loader, IMG_EXTENSIONS from torch.utils.data import DataLoader import torchvision.transforms as transforms class ImageFolderGrayColor(ImageFolder): def __init__( self, root, transform=None, target_transform=None, ): super(ImageFolder, self).__init__(root=root, loader=default_loader, transform=transform, extensions=IMG_EXTENSIONS, target_transform=target_transform) #TODO \u00e0 modifier def __getitem__(self, index): \"\"\" Args: index (int): Index Returns: tuple: (sample, target) where target is class_index of the target class. \"\"\" path, _ = self.samples[index] sample = self.loader(path) if self.target_transform is not None: target = self.target_transform(sample) if self.transform is not None: sample = self.transform(sample) return sample, target def get_colorized_dataset_loader(path, **kwargs): source_process = transforms.Compose( [transforms.Resize((224, 224)), transforms.Grayscale(num_output_channels=1), transforms.ToTensor(), transforms.Normalize(mean=[0.5], std=[0.5])]) target_process = transforms.Compose( [transforms.Resize((224, 224)), transforms.ToTensor()]) dataset = ImageFolderGrayColor(path, source_process, target_process) return DataLoader(dataset, **kwargs) Create a new file colorize.py and fill the train method in the following canvas (you can inspire yourself from the one in the MNIST example. Be careful, however, in your criterion choice): import argparse # to parse script arguments from statistics import mean # to compute the mean of a list from tqdm import tqdm #used to generate progress bar during training import torch import torch.optim as optim from torch.utils.tensorboard import SummaryWriter from torchvision.utils import make_grid #to generate image grids, will be used in tensorboard from data_utils import get_colorized_dataset_loader # dataloarder from unet import UNet # setting device on GPU if available, else CPU device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') def train(net, optimizer, loader, epochs=5, writer=None): criterion = ... for epoch in range(epochs): running_loss = [] t = tqdm(loader) for x, y in t: # x: black and white image, y: colored image ... ... ... ... ... ... ... ... if writer is not None: #Logging loss in tensorboard writer.add_scalar('training loss', mean(running_loss), epoch) # Logging a sample of inputs in tensorboard input_grid = make_grid(x[:16].detach().cpu()) writer.add_image('Input', input_grid, epoch) # Logging a sample of predicted outputs in tensorboard colorized_grid = make_grid(outputs[:16].detach().cpu()) writer.add_image('Predicted', colorized_grid, epoch) # Logging a sample of ground truth in tensorboard original_grid = make_grid(y[:16].detach().cpu()) writer.add_image('Ground truth', original_grid, epoch) return mean(running_loss) if __name__=='__main__': parser = argparse.ArgumentParser() parser.add_argument('--data_path', type=str, default = 'data/landscapes', help='dataset path') parser.add_argument('--batch_size', type=int, default = int(32), help='batch_size') parser.add_argument('--epochs', type=int, default = int(10), help='number of epochs') parser.add_argument('--lr', type=float, default = float(1e-3), help='learning rate') args = parser.parse_args() data_path = args.data_path batch_size = args.batch_size epochs = args.epochs lr = args.lr unet = UNet().cuda() loader = get_colorized_dataset_loader(path=data_path, batch_size=batch_size, shuffle=True, num_workers=4) optimizer = optim.Adam(unet.parameters(), lr=lr) writer = SummaryWriter('runs/UNet') train(unet, optimizer, loader, epochs=epochs, writer=writer) writer.add_graph(unet) # Save model weights torch.save(unet.state_dict(), 'unet.pth')","title":"Training script"},{"location":"gcloud.html#training-on-gcloud","text":"You now have everything to run your code on GCloud. Fire up your GCloud instance. On a terminal, connect to your instance using the following command (replace the zone and instance name with yours): gcloud compute ssh --zone \"europe-west1-d\" \"your_instance_name\" Create a folder Workspace on your virtual machine: mkdir Workspace You can copy a file from your local machine to the virtual machine using the following command on your local terminal: gcloud compute scp [your_file_path] your_instance_name:Workspace/ --zone \"europe-west1-d\" Conversly, you can copy a from your virtual machine to your local machine the following command on your local terminal: gcloud compute scp bsf.pth your_instance_name:Workspace/ --zone \"europe-west1-d\" Add the --recurse argument to your command if you want to copy a folder. Copy the folder containing all your code into your virtual machine's Workspace folder. Also, copy the download_landscapes.sh file into your VM and execute it. You should now be able to run your python script and thus learn to colorize images. Run your script for one entire epoch to check that everything is working fine. We will now run our script for a few more epochs, but before that, we will create an ssh tunnel between our local machine and the virtual machine. Run the following command on your local machine with the correct name for your virtual machine (use your correct zone). gcloud compute ssh --ssh-flag=\"-L 8898:localhost:8898\" --zone \"us-central1-b\" \"example_instance_name\" This command connects you to your virtual machine and forwards its port 8898 to your local machine's port 8898 (you can change the port value if needed). Thanks to that, you will get access to the tensorboard interface running on the virtual machine through your local machine. Now on this terminal window, run the following command: tensorboard --logdir runs --port 8898 On another terminal, connect to your virtual machine and run your script with a few more epochs (like 10 for instance). On your web browser, go to the following adress: http://localhost:8898/ You should be able to access tensorboard. Check on your network graph. You should see the U shape of your Unet. You can now visualize the progression of your network while it is training in the images tab.","title":"Training on GCloud"},{"location":"gcloud.html#bonus-synchronize-with-rsync","text":"An easy way to synchronize your code with your VM is to use rsync Install rsync on your virtual machine : sudo apt-get install rsync Add the public key you\u2019re going to use to connect to the VM to the VM\u2019s ~/.ssh/authorized_keys On the virtual machine: touch ~/.ssh/authorized_keys nano ~/.ssh/authorized_keys Copy the content of your public key (It is usually located in ~/.ssh/id_rsa.pub on your local machine) in the opened file. Press ctrl+x then y then enter to save. Now to synchronize a folder, find the IP of your virtual machine in the GCloud interface: To synchronize your folder on your local machine (for instance, named test_gcloud ) with a distant folder on the virtual machine (located, for example, in Workspace/test_gcloud): rsync -r [VM_IP_ADRESS]:Workspace/test_gcloud/ test_gcloud/ To synchronize a distant folder on the virtual machine with a folder on your local machine : rsync -r test_gcloud/ [VM_IP_ADRESS]:Workspace/test_gcloud/ You can find more information on the rsync command here (in french) You can stop your VM using the GCloud interface or just by running the following command: sudo shutdown -h now","title":"Bonus synchronize with Rsync"},{"location":"gcloud_set_up.html","text":"Set up GCloud: Google sponsors this course with free GCloud credits through the Cloud Higher Education Programs. Go to this link to claim your coupon code for the credits associated with this course. Once you have your coupon code go to this link to get your credits (you will need a Google account, if needed, you can create one using your INSA mail address). Once you are on the GCloud homepage, start by creating a new project: Once your project is created go to Compute Engine -> VM instances and activate Compute Engine API for your project . You now need to add GPU capacity to your project. Go to IAM and admin -> Quotas . On the filter select Quota and K80 GPUs(all regions) and click on modify quotas . Increase the limit to one and add a short description to your request: Hi, I am a student enrolled at INSA Toulouse. The GCloud Higher education program granted us free credits. These credits are associated with a course in which the practical sessions will require access to GPU machines. Would you please increase my GPU quota so I can participate to the practical sessions? Many thanks, You name This process may take some time. Therefore, be sure sure to complete every steps at least a few days before the practical session. You will also need to install the Cloud SDK Command-line interface. It should already be installed on the INSA's machines. If you are using your personal computer, follow the corresponding installation procedure available here . Once the GCloud SDK is configured on your local machine, go to your GCloud interface and go to Compute engine ->VM instances Click on the create new instance button to create your first instance. Be sure at this point that your quota request has been approved or you will not be able to attach a GPU to your Virtual Machine. Now create a new instance on the same region you asked for your GPU quota. You may follow the following parameters settings for the practical session. Select the following hard drive options Finally, check the two checkboxes at the bottom of the page to allow Http/Https traffic. After a few minutes your instance should be created. It should appear in the VM instance panel: If its status is in green, the virtual machine is started and consuming your free credit. Go to ssh -> show ssh the gcloud command and copy the command on your terminal. You should now be connected to your virtual machine and see the following output on your terminal: Type 'y' to install the nvidia drivers. If the drivers failed to be installed and you obtain the following message: Wait a few minutes and type: cd /opt/deeplearning/ sudo ./install-driver.sh To verify that everything is correctly installed type the following command nvidia-smi If you see something like +-----------------------------------------------------------------------------+ | NVIDIA-SMI 460.73.01 Driver Version: 460.73.01 CUDA Version: 11.2 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla K80 Off | 00000000:00:04.0 Off | 0 | | N/A 36C P0 69W / 149W | 0MiB / 11441MiB | 100% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ then your installation is complete and you can stop your virtual machine until the practical session using the GCloud web interface or typing the following command: sudo shutdown -h now Be sur to do all this process before the practical session, it will save you many time and remenber at least to ask for your quotas as soon as possible!","title":"Set up GCloud:"},{"location":"gcloud_set_up.html#set-up-gcloud","text":"Google sponsors this course with free GCloud credits through the Cloud Higher Education Programs. Go to this link to claim your coupon code for the credits associated with this course. Once you have your coupon code go to this link to get your credits (you will need a Google account, if needed, you can create one using your INSA mail address). Once you are on the GCloud homepage, start by creating a new project: Once your project is created go to Compute Engine -> VM instances and activate Compute Engine API for your project . You now need to add GPU capacity to your project. Go to IAM and admin -> Quotas . On the filter select Quota and K80 GPUs(all regions) and click on modify quotas . Increase the limit to one and add a short description to your request: Hi, I am a student enrolled at INSA Toulouse. The GCloud Higher education program granted us free credits. These credits are associated with a course in which the practical sessions will require access to GPU machines. Would you please increase my GPU quota so I can participate to the practical sessions? Many thanks, You name This process may take some time. Therefore, be sure sure to complete every steps at least a few days before the practical session. You will also need to install the Cloud SDK Command-line interface. It should already be installed on the INSA's machines. If you are using your personal computer, follow the corresponding installation procedure available here . Once the GCloud SDK is configured on your local machine, go to your GCloud interface and go to Compute engine ->VM instances Click on the create new instance button to create your first instance. Be sure at this point that your quota request has been approved or you will not be able to attach a GPU to your Virtual Machine. Now create a new instance on the same region you asked for your GPU quota. You may follow the following parameters settings for the practical session. Select the following hard drive options Finally, check the two checkboxes at the bottom of the page to allow Http/Https traffic. After a few minutes your instance should be created. It should appear in the VM instance panel: If its status is in green, the virtual machine is started and consuming your free credit. Go to ssh -> show ssh the gcloud command and copy the command on your terminal. You should now be connected to your virtual machine and see the following output on your terminal: Type 'y' to install the nvidia drivers. If the drivers failed to be installed and you obtain the following message: Wait a few minutes and type: cd /opt/deeplearning/ sudo ./install-driver.sh To verify that everything is correctly installed type the following command nvidia-smi If you see something like +-----------------------------------------------------------------------------+ | NVIDIA-SMI 460.73.01 Driver Version: 460.73.01 CUDA Version: 11.2 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla K80 Off | 00000000:00:04.0 Off | 0 | | N/A 36C P0 69W / 149W | 0MiB / 11441MiB | 100% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ then your installation is complete and you can stop your virtual machine until the practical session using the GCloud web interface or typing the following command: sudo shutdown -h now Be sur to do all this process before the practical session, it will save you many time and remenber at least to ask for your quotas as soon as possible!","title":"Set up GCloud:"},{"location":"git_intro.html","text":"Introduction to git","title":"Introduction to Git"},{"location":"git_intro.html#introduction-to-git","text":"","title":"Introduction to git"},{"location":"interpretability.html","text":"Interpretability in Machine Learning Practical session Practical session Solution","title":"Interpretability in Machine Learning"},{"location":"interpretability.html#interpretability-in-machine-learning","text":"","title":"Interpretability in Machine Learning"},{"location":"interpretability.html#practical-session","text":"Practical session Solution","title":"Practical session"},{"location":"introduction.html","text":"Course Introduction:","title":"Course Introduction"},{"location":"introduction.html#course-introduction","text":"","title":"Course Introduction:"},{"location":"policy_gradient.html","text":"Introduction to Reinforcement Learning: Policy Gradient Slides Practical session","title":"Introduction to Reinforcement Learning:"},{"location":"policy_gradient.html#introduction-to-reinforcement-learning","text":"","title":"Introduction to Reinforcement Learning:"},{"location":"policy_gradient.html#policy-gradient","text":"Slides Practical session","title":"Policy Gradient"},{"location":"q_learning.html","text":"Introduction to Reinforcement Learning: From policy iteration to Deep Q-Learning Slides Practical sessions: Policy iteration and Value Iteration Q-learning Deep Q-learning","title":"Introduction to Reinforcement Learning:"},{"location":"q_learning.html#introduction-to-reinforcement-learning","text":"","title":"Introduction to Reinforcement Learning:"},{"location":"q_learning.html#from-policy-iteration-to-deep-q-learning","text":"Slides Practical sessions: Policy iteration and Value Iteration Q-learning Deep Q-learning","title":"From policy iteration to Deep Q-Learning"},{"location":"rec_sys.html","text":"Recommendation Systems Slides Practical session Solution","title":"Recommendation Systems"},{"location":"rec_sys.html#recommendation-systems","text":"Slides Practical session Solution","title":"Recommendation Systems"},{"location":"rl.html","text":"Introduction to Reinforcement Learning: Optional (last year course on Policy gradients methods): Slides Intro Slides Policy gradients Practical sessions: Policy iteration and Value Iteration Solution: Q-learning Solution: Deep Q-learning Solution:","title":"Introduction to Reinforcement Learning:"},{"location":"rl.html#introduction-to-reinforcement-learning","text":"Optional (last year course on Policy gradients methods): Slides Intro Slides Policy gradients Practical sessions: Policy iteration and Value Iteration Solution: Q-learning Solution: Deep Q-learning Solution:","title":"Introduction to Reinforcement Learning:"},{"location":"schedule.html","text":"Schedule Lectures : 10 hours Practical Sessions : 30 hours. Fives days are dedicated to the practical sessions. All the lectures associated to each sessions are available in video. You must have seen the corresponding videos before each session. At the start of each practical session, approximately 15 minutes will be devoted to questions about the lectures. Session 1 Course Introduction : Course Introduction Development for Data Scientist : Introduction to Pytorch and Python scripts Introduction to Git : Introduction to Git Development for Data Scientist : Introduction to Docker Session 2 Explainable AI Session 3 Recommender Systems Session 4 Introduction to Reinforcement learning:","title":"Schedule"},{"location":"schedule.html#schedule","text":"Lectures : 10 hours Practical Sessions : 30 hours. Fives days are dedicated to the practical sessions. All the lectures associated to each sessions are available in video. You must have seen the corresponding videos before each session. At the start of each practical session, approximately 15 minutes will be devoted to questions about the lectures.","title":"Schedule"},{"location":"schedule.html#session-1","text":"Course Introduction : Course Introduction Development for Data Scientist : Introduction to Pytorch and Python scripts Introduction to Git : Introduction to Git Development for Data Scientist : Introduction to Docker","title":"Session 1"},{"location":"schedule.html#session-2","text":"Explainable AI","title":"Session 2"},{"location":"schedule.html#session-3","text":"Recommender Systems","title":"Session 3"},{"location":"schedule.html#session-4","text":"Introduction to Reinforcement learning:","title":"Session 4"},{"location":"text1.html","text":"Text Cleaning and Text Vectorization Slides Practical session","title":"Text Cleaning and Text Vectorization"},{"location":"text1.html#text-cleaning-and-text-vectorization","text":"Slides Practical session","title":"Text Cleaning and Text Vectorization"},{"location":"text2.html","text":"Words Embedding Slides Practical session","title":"Words Embedding"},{"location":"text2.html#words-embedding","text":"Slides Practical session","title":"Words Embedding"},{"location":"text3.html","text":"Text Recurrent Network Slides Practical session","title":"Text Recurrent Network"},{"location":"text3.html#text-recurrent-network","text":"Slides Practical session","title":"Text Recurrent Network"}]}